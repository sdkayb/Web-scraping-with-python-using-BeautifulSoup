{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PROJET PYTHON POUR LA DATA SCIENCE :\n",
    "## PAR : ELARNI Maroua & SADKI Ayoub  \n",
    "***\n",
    "## SCRAPING DU SITE AVITO.MA\n",
    "***\n",
    "***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques nécessaires :\n",
    "### BeautifulSoup requests numpy et pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime , timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Initialisation des variables :\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "\n",
    "#initialisation des compteurs de nombre d'annonces pour chaque catégorie qui va aussi servir pour key dans le dictionnaire par lequel on va créer les dataframes\n",
    "nbr_ann , nbr_veh , nbr_imm , nbr_info , nbr_maison  , nbr_emp , nbr_hab , nbr_lois , nbr_entr , nbr_autr = 0,0,0,0,0,0,0,0,0,0\n",
    "\n",
    "#initialisation des dataframe de chaque catégorie \n",
    "df_veh = pd.DataFrame(columns =['titre' , 'description','catégorie','prix', 'devise','ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien']) \n",
    "df_info = pd.DataFrame(columns =['titre','description','catégorie','prix' , 'devise', 'ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien']) \n",
    "df_maison=pd.DataFrame(columns =['titre','description','catégorie','prix','devise','ville','professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien']) \n",
    "df_imm = pd.DataFrame(columns =['titre','description','catégorie','prix','devise','ville', 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien']) \n",
    "df_emp = pd.DataFrame(columns =['titre','description','catégorie','prix','devise','ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien']) \n",
    "df_hab = pd.DataFrame(columns =['titre','description','catégorie','prix' , 'devise','ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien']) \n",
    "df_lois = pd.DataFrame(columns =['titre','description','catégorie','prix','devise','ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien']) \n",
    "df_entr = pd.DataFrame(columns =['titre','description','catégorie','prix','devise','ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien']) \n",
    "df_autr = pd.DataFrame(columns =['titre','description','catégorie','prix','devise','ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien'])\n",
    "\n",
    "#fonction qui sépare un dictionnaire en deux listes de meme ordre keys et values \n",
    "def split_keys_values(d):\n",
    "    keys = []\n",
    "    values = []\n",
    "    for k in d:\n",
    "        keys.append(k)\n",
    "        values.append(d[k])\n",
    "    return ([keys , values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Prendre le lien a scraper (site avito):\n",
    "https://www.avito.ma/fr/maroc/\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entrer le lien d'annonces que vous voulez scrapper (le lien doit être une page de recherche du site avito qui possède 35 annonces ) : https://www.avito.ma/fr/maroc/\n"
     ]
    }
   ],
   "source": [
    "#on entre (copier/coller) le lien du site dans la variable url de type str\n",
    "\n",
    "################# \"\"\"'''''' le lien le plus standard est : {{{{{{{{{{{{{{      'https://www.avito.ma/fr/maroc/'    }}}}}}}}}}}}}} ''''''''\"\"\" ######################\n",
    "\n",
    "url = input(\"entrer le lien d'annonces que vous voulez scrapper (le lien doit être une page de recherche du site avito qui possède 35 annonces ) : \")\n",
    "\n",
    "#on prend le codesource du site \n",
    "code = requests.get(url).text\n",
    "soup = BeautifulSoup(code,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Code:\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entrer le nombre d'annonces que vous voulez scrapper (multiple de 35) : 1050\n",
      "\n",
      "Execution time: 478.75840640068054 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "begin = time.time() #initialiser un timer\n",
    "#entrer le nombre d'annonces qu'on veut scraper\n",
    "n = int(input(\"entrer le nombre d'annonces que vous voulez scrapper (multiple de 35) : \")) \n",
    "while True : \n",
    "    if nbr_ann > n :\n",
    "        break\n",
    "    annonces = soup.find_all('h2' , {'class' : 'fs14'}) #liste des annoces de la page actuelle\n",
    "    for annonce in annonces :\n",
    "        link = annonce.find('a').get('href')   #lien de l'annonce en cours\n",
    "        code_in = requests.get(link).text     #code source de l'annoce en cours\n",
    "        soup_in = BeautifulSoup(code_in,'html.parser')   \n",
    "        if soup_in.find('h1' , {'class' : 'page-header mbm'}) : #condition qui vérifie si l'annonce existe bel et bien (des fois le lien existe mais l'annonce est vide car le produit est vendu) \n",
    "            nbr_ann += 1 #incrémentation du compteur de nombre d'annonces totale\n",
    "            cat = soup_in.find('ol',{'class' : 'breadcrumb'}).find_all('span')[-2].text.strip()  # catégorie de l'annonce en cours\n",
    "            s_cat = soup_in.find('ol' , {'class' : 'breadcrumb'}).find_all('span')[-1].text.strip()  #sous catégorie de l'annonce en cours\n",
    "            titre = soup_in.find('h1' , {'class' : 'page-header mbm'}).text.strip().split('\\n')[0] # titre de l'annoce en cours\n",
    "            vues = int(soup_in.find_all('div' , {'class' : 'panel-heading panel-heading-small'})[0].text.split()[1])  #nombre de vues de l'annonce en cours\n",
    "            nom = soup_in.find('div' , {'class' : 'panel-footer'}).find('strong').text # nom de l'annonceur de l'annonce en cours\n",
    "            date_heure = soup_in.find('abbr' , {'class' : 'date dtstart value'}).text.strip()  #date et heure de post de l'annonce en cours (séparé après dans Date et heure)\n",
    "            if date_heure.split()[0] == \"Aujourd'hui\":\n",
    "                Date = datetime.today().strftime('%d %b') \n",
    "            elif date_heure.split()[0] == 'Hier':\n",
    "                Date = (datetime.today() - timedelta(days=1)).strftime('%d %b')\n",
    "            else : \n",
    "                Date = ' '.join(date_heure.split()[0:2])\n",
    "\n",
    "            heure = date_heure.split()[-1]\n",
    "            prix_tag = soup_in.find('span' , {'class' : 'amount value'})   \n",
    "            prix = float(prix_tag.text.replace(\" \", \"\")) if prix_tag else nan #prix de l'annonce en cours\n",
    "            devise_tag = soup_in.find('abbr' , {'class' : 'currency'})\n",
    "            devise = devise_tag.text if devise_tag else nan  #devise de l'annonce en cours \n",
    "            pro_par_tag = soup_in.find('small' , {'class' : 'label'})\n",
    "            pro_par = 'professionnel' if pro_par_tag else \"particulier\"  #type de l'annonce en cours (professionel ou bien particulier)                          \n",
    "            desc_tag = soup_in.find('div' , {'class' : 'span10'}).find_all('p') \n",
    "            desc = ''\n",
    "            for d in desc_tag:\n",
    "                desc += d.text[1:]\n",
    "            desc = desc.strip()   #desctiption de l'annonce en cours \n",
    "            loc = soup_in.find('h2' , {'class' : 'font-normal fs13 lh30 no-margin'}).text.strip() #localisation de l'annonce en cours\n",
    "            \n",
    "            #numéro de téléphone de l'annonce en cours\n",
    "            if  'telephone: \"0' in  code_in :\n",
    "                index = code_in.index('telephone: \"0')\n",
    "                tel = 'MA: +212-' + code_in[index + 13 : index + 22]\n",
    "            else:\n",
    "                tel = np.nan   \n",
    "                \n",
    "            #informations supplémentaires prises de manière dynamique \n",
    "            #ces infos  n'existent pas dans toutes les annonces \n",
    "            #du coup si les infos existent on les prends et on les met dans un dictionnaire 'autres'\n",
    "            #avec les keys sont les intitulés et les values sont l'information présentée\n",
    "            autres_tag  = soup_in.find('aside').find('ul').find_all('h2')\n",
    "            autres = {}\n",
    "            for autre in autres_tag:\n",
    "                if autre.find('strong') and autre.find('a'):\n",
    "                    autres[autre.find('strong').text.strip()[:-1]] = autre.find('a').text.strip()\n",
    "\n",
    "                elif autre.find('strong') :\n",
    "                    if len(autre.text.split(':')[1].strip()) > 1 :\n",
    "                        autres[autre.find('strong').text.strip()[:-1]] = autre.text.split(':')[1].strip()\n",
    "                    else :\n",
    "                        autres[autre.find('strong').text.strip()[:-1]] = nan \n",
    "        \n",
    "#############################################################################################################\n",
    "            #on check la catégorie de l'annonce en cours \n",
    "            #on traite les chaines de caractère on les rends int pour  les  colonnes nécessaires \n",
    "            #pour chaque catégorie on crée une dataframe composée d'une seule ligne (l'annonce en cours) qui sera appendé  à la dataframe initiale\n",
    "            if s_cat in ['Engins Agricole' , 'Remorques Et Caravanes' , 'Engins Btp' , 'Camions' ]:\n",
    "                cat = 'Véhicules'\n",
    "\n",
    "            if cat.lower() == 'vehicules' : #or s_cat in ['Engins Agricole' , 'Remorques Et Caravanes' , 'Engins Btp' , 'Camions' ]:\n",
    "                nbr_veh += 1\n",
    "\n",
    "                if 'Année-Modèle' in autres and autres['Année-Modèle'] is not nan :\n",
    "                    autres['Année-Modèle'] = int(autres['Année-Modèle'].split()[0])\n",
    "\n",
    "                if 'Kilométrage' in autres and autres['Kilométrage'] is not nan : \n",
    "                    autres['Kilométrage'] = autres['Kilométrage'][-7:]\n",
    "                    if autres['Kilométrage'][0] == '-':\n",
    "                        autres['Kilométrage'] = int(autres['Kilométrage'][1:].strip().replace(' ',''))\n",
    "                    else :\n",
    "                        autres['Kilométrage'] = int(autres['Kilométrage'].strip().replace(' ' , '')) \n",
    "\n",
    "                k_v = split_keys_values(autres)\n",
    "\n",
    "                d_veh = {}      \n",
    "                d_veh[nbr_veh] = ([titre , desc , cat , prix , devise , loc , pro_par ,  vues , nom , tel , Date , heure ,link]+ k_v[1] )\n",
    "                df_veh = df_veh.append(pd.DataFrame.from_dict(d_veh,  orient = 'index'  , columns = (['titre' , 'description' , 'catégorie' , 'prix' , 'devise' , 'ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien'] + k_v[0])))\n",
    "\n",
    "            elif cat.lower() == 'immobilier' :   \n",
    "                nbr_imm += 1\n",
    "                if 'Nombre de pièces' in autres:\n",
    "                    autres['Nombre de pièces']=int(autres['Nombre de pièces'])\n",
    "                if 'Surface totale' in autres and type(autres['Surface totale']) != float : \n",
    "                    autres['Surface totale'] = float(autres['Surface totale'].split()[0]) \n",
    "                k_v = split_keys_values(autres)     \n",
    "                d_imm = {}\n",
    "                d_imm[nbr_imm] = ([titre , desc , cat ,   prix , devise , loc ,   pro_par ,  vues , nom , tel , Date , heure ,link] + k_v[1])                                                                                                                                                                                                                                      \n",
    "                df_imm = df_imm.append(pd.DataFrame.from_dict(d_imm,  orient = 'index'  , columns = (['titre' , 'description' , 'catégorie' , 'prix' , 'devise' , 'ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien'] + k_v[0])))\n",
    "\n",
    "            elif cat.lower() == 'informatique et multimedia' : \n",
    "                nbr_info += 1\n",
    "                k_v = split_keys_values(autres)\n",
    "                d_info = {}\n",
    "                d_info[nbr_info] = ([titre , desc , cat , prix , devise , loc , pro_par ,  vues , nom , tel , Date , heure ,link] + k_v[1])  \n",
    "                df_info = df_info.append(pd.DataFrame.from_dict(d_info,  orient = 'index'  , columns = (['titre' , 'description' , 'catégorie' , 'prix' , 'devise' , 'ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien'] + k_v[0])))\n",
    "\n",
    "            elif cat.lower() == 'pour la maison et jardin' :\n",
    "                nbr_maison += 1\n",
    "                k_v = split_keys_values(autres)\n",
    "                d_maison = {}\n",
    "                d_maison[nbr_maison] = ([titre , desc , cat ,   prix , devise , loc ,   pro_par ,  vues , nom , tel , Date , heure ,link] + k_v[1])   \n",
    "                df_maison = df_maison.append(pd.DataFrame.from_dict(d_maison,  orient = 'index'  , columns = (['titre' , 'description' , 'catégorie' , 'prix' , 'devise' , 'ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien'] + k_v[0])))\n",
    "\n",
    "            elif cat.lower() == 'emploi et services' :\n",
    "                nbr_emp += 1\n",
    "                k_v = split_keys_values(autres)\n",
    "                d_emp = {}\n",
    "                d_emp[nbr_emp] = ([titre , desc , cat ,   prix , devise , loc ,   pro_par ,  vues , nom , tel , Date , heure ,link] + k_v[1])   \n",
    "                df_emp = df_emp.append(pd.DataFrame.from_dict(d_emp,  orient = 'index'  , columns = (['titre' , 'description' , 'catégorie' , 'prix' , 'devise' , 'ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien'] + k_v[0])))\n",
    "\n",
    "            elif cat.lower() == 'habillement et bien etre':\n",
    "                nbr_hab += 1\n",
    "                k_v = split_keys_values(autres)\n",
    "                d_hab = {}\n",
    "                d_hab[nbr_hab] = ([titre , desc , cat ,   prix , devise , loc ,   pro_par ,  vues , nom , tel , Date , heure ,link] + k_v[1])   \n",
    "                df_hab = df_hab.append(pd.DataFrame.from_dict(d_hab,  orient = 'index'  , columns = (['titre' , 'description' , 'catégorie' , 'prix' , 'devise' , 'ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien'] + k_v[0])))\n",
    "\n",
    "            elif cat.lower() == 'loisirs et divertissement':\n",
    "                nbr_lois += 1\n",
    "                k_v = split_keys_values(autres)\n",
    "                d_lois = {}\n",
    "                d_lois[nbr_lois] = ([titre , desc , cat ,   prix , devise , loc ,   pro_par ,  vues , nom , tel , Date , heure ,link] + k_v[1])   \n",
    "                df_lois = df_lois.append(pd.DataFrame.from_dict(d_lois,  orient = 'index'  , columns = (['titre' , 'description' , 'catégorie' , 'prix' , 'devise' , 'ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien'] + k_v[0])))\n",
    "\n",
    "            elif cat.lower() == 'entreprises': \n",
    "                nbr_entr += 1 \n",
    "                k_v = split_keys_values(autres)\n",
    "                d_entr = {}\n",
    "                d_entr[nbr_entr] = ([titre , desc , cat ,   prix , devise , loc ,   pro_par ,  vues , nom , tel , Date , heure ,link] + k_v[1])   \n",
    "                df_entr = df_entr.append(pd.DataFrame.from_dict(d_entr,  orient = 'index'  , columns = (['titre' , 'description' , 'catégorie' , 'prix' , 'devise' , 'ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien'] + k_v[0])))\n",
    "\n",
    "            elif cat.lower() == 'autres':\n",
    "                nbr_autr += 1\n",
    "                k_v = split_keys_values(autres)\n",
    "                d_autr = {}\n",
    "                d_autr[nbr_autr] = ([titre , desc , cat ,   prix , devise , loc ,   pro_par ,  vues , nom , tel , Date , heure ,link] + k_v[1])  \n",
    "                df_autr = df_autr.append(pd.DataFrame.from_dict(d_autr,  orient = 'index'  , columns = (['titre' , 'description' , 'catégorie' , 'prix' , 'devise' , 'ville' , 'professionnel/particulier' , 'vues' , 'nom' , 'telephone' , 'Date' , 'Heure', 'lien'] + k_v[0])))\n",
    "    #le codesource  de la page suivante\n",
    "    soup = BeautifulSoup(requests.get(soup.find('div' , {'class' : 'pagination text-center mt-2'}).find_all('li')[-1].find('a').get('href')).text,'html.parser')\n",
    "\n",
    "end = time.time() #fin du timer\n",
    "print('\\nExecution time: ' + str(((end-begin))) + ' s\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ~ traitement de quelques colonnes : \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertion des colonnes Année-Modèle et Kilométrage en int car\n",
    "#les colonnes Année-Modèle et Kilométrage dans la data frame de la catégorie véhicules était affiché sous forme de float \n",
    "#car nan était considéré comme tel par la dataframe et que la colonne devait etre du meme type \n",
    "#du coup ils étaient reconvertis en float a chaque fois\n",
    "\n",
    "df_veh[['Année-Modèle']] = df_veh[['Année-Modèle']].astype('Int64')\n",
    "df_veh[['Kilométrage']] = df_veh[['Kilométrage']].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Dataframe to csv: \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#concaténation des dataframe de toute les catégorie en une seule df_avito\n",
    "pdList = [df_veh , df_imm ,  df_info , df_maison , df_lois , df_emp , df_hab , df_entr , df_autr]  \n",
    "dfList = ['vehicules' , 'immobilier' ,  'informatique' , 'maison' , 'loisir' , 'emploi' , 'habillement' , 'entreprise' , 'autres']  \n",
    "df_avito = pd.concat(pdList , ignore_index=True)\n",
    "\n",
    "#création des fichier csv  a partir des dataframe pour chaque catégorie\n",
    "df_veh.to_csv('vehi.csv' , index= False )\n",
    "df_imm.to_csv('immo.csv' , index= False )\n",
    "df_info.to_csv('infor.csv' , index= False )\n",
    "df_lois.to_csv('loisi.csv' , index= False )\n",
    "df_maison.to_csv('mais.csv' , index= False )\n",
    "df_emp.to_csv('empl.csv' , index= False )\n",
    "df_entr.to_csv('entre.csv' , index= False )\n",
    "df_autr.to_csv('autre.csv' , index= False )\n",
    "df_hab.to_csv('habi.csv' , index= False )\n",
    "df_avito.to_csv('avito.csv' , index= False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
